---

- name: Build HDP3.3
  gather_facts: false
  hosts: all
  become: yes
  tasks:
    - name: Create hadoop user
      user:
        name: hadoop
        generate_ssh_key: yes
        ssh_key_bits: 4096
        ssh_key_file: .ssh/id_rsa

#    - name: Install Java 11
#      yum:
#        name: "{{packages}}"
#        state: latest
#      vars:
#        packages:
#        - java-11-openjdk-devel


- hosts: master
  become: yes
  tasks:
    - name: Create authorized_keys file
      shell:
        cmd: cp /home/hadoop/.ssh/id_rsa.pub /home/hadoop/.ssh/authorized_keys
    
    - name: Push keys to nodes
      shell:
        cmd: scp -r .ssh {{ item }}:/home/hadoop/
        chdir: /home/hadoop
      loop:
        - node1
        - node2

    - name: Get Hadoop distribution checksum
      get_url:
        url: https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz.sha512
        dest: /var/tmp/

    - name: Store checksum
      slurp:
        src: /var/tmp/hadoop-3.3.0.tar.gz.sha512
      register: hdp_checksum64

    - name: Get Hadoop distribution
      get_url: 
        url: https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
        dest: /var/tmp/
        checksum: "sha512:{{ hdp_checksum.split( )[3] }}"
      vars:
        hdp_checksum: '{{ hdp_checksum64.content | b64decode }}'

    - name: Unpack hadoop distribution
      unarchive:
        src: /var/tmp/hadoop-3.3.0.tar.gz
        dest: /opt
        owner: hadoop
        group: hadoop
        remote_src: yes

    - name: Create Hadoop Version Symlink
      file:
        src: /opt/hadoop-3.3.0
        dest: /opt/hadoop
        owner: hadoop
        group: hadoop
        state: link

    - name: Update Hadoop Java path
      lineinfile:
        path: /opt/hadoop/etc/hadoop/hadoop-env.sh
        regexp: 'export JAVA_HOME'
        line: export JAVA_HOME=/usr/lib/jvm/jre-11

    - name: Update core-site.xml
      get_url:
        url: https://raw.githubusercontent.com/jpclouduk/HDP33/master/config/core-site.xml
        dest: /hadoop/etc/hadoop/core-site.xml

    - name: Update hdfs-site.xml
      get_url:
        url: https://raw.githubusercontent.com/jpclouduk/HDP33/master/config/hdfs-site.xml
        dest: /hadoop/etc/hadoop/hdfs-site.xml

    - name: Update mapred-site.xml
      get_url:
        url: https://raw.githubusercontent.com/jpclouduk/HDP33/master/config/mapred-site.xml
        dest: /hadoop/etc/hadoop/mapred-site.xml

    - name: Update yarn-site.xml
      get_url:
        url: https://raw.githubusercontent.com/jpclouduk/HDP33/master/config/yarn-site.xml
        dest: /hadoop/etc/hadoop/yarn-site.xml

    - name: Push hadoop build to workers
      shell:
        cmd: scp -r hadoop {{ item }}:/opt/
        chdir: /opt
      loop:
        - node1
        - node2


- hosts: all
  become: yes
  tasks:

    - name: Set permissions on hadoop ssh keys
      file:
        path: /home/hadoop/.ssh
        owner: hadoop
        group: hadoop
        recurse: yes
        mode: '0600'
    
    - name: Set permissions on hadoop ssh dir
      file:
        path: /home/hadoop/.ssh
        owner: hadoop
        group: hadoop
        mode: '0700'
  
    - name: Set permissions on hadoop build
      file:
        path: /opt/hadoop
        owner: hadoop
        group: hadoop
        recurse: yes

    - name: Create hadoop data directory
      file:
        path: /data
        state: directory
        owner: hadoop
        group: hadoop
        mode: '0755'

    - name: Setup hadoop PATH
      lineinfile:
        path: /home/hadoop/.bashrc
        regexp: '^PATH='
        line: PATH=/opt/hadoop/bin:/opt/hadoop/sbin:$PATH

    - name: Setup HADOOP_HOME
      lineinfile:
        path: /home/hadoop/.bashrc
        regexp: '^HADOOP_HOME='
        line: HADOOP_HOME=/opt/hadoop

    - name: Setup Export
      lineinfile:
        path: /home/hadoop/.bashrc
        regexp: '^export'
        line: export PATH HADOOP_HOME


- hosts: master
  become: yes
  tasks:

    - name: Format hdfs
      shell:
        cmd: /bin/su -c "hdfs namenode format" - hadoop

    - name: Start hadoop
      shell:
        cmd: /bin/su -c "start-dfs.sh" - hadoop


